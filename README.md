# ğŸ¤– Gremmy-Chatbot

**GEN AI: Gremmy Chatbot made as a Knowledge Assistant**

Gremmy is a lightweight chatbot powered by Large Language Models (LLMs) that allows you to have natural conversations with an AI assistant. Itâ€™s designed to help users explore ideas, ask questions, or simply chat with a friendly, intelligent bot.

---

## ğŸŒ Try It Online

ğŸš€ **Live Demo (Powered by Google Gemma LLM)**  
You can chat with Gremmy online via Hugging Face Spaces:  
ğŸ”— [https://huggingface.co/spaces/Enoch1359/LLm_file](https://huggingface.co/spaces/Enoch1359/LLm_file)

---

## ğŸ“¦ Features

- ğŸ’¬ Chat with an AI assistant powered by LLM (Large Language Model)

---

## ğŸ§ª Use Cases

- Have natural conversations with an AI
- Ask general knowledge or learning-related questions
- Use it as a virtual companion or tutor

---

## ğŸ› ï¸ Tech Stack

- `Python 3.10+`
- `Streamlit` â€“ for the web interface
- `OpenAI API` â€“ for GPT-based responses
- `Google Gemma` â€“ open-source LLM from Google  
- `dotenv` â€“ to manage API keys securely
- `Docker` â€“ for containerized deployment (optional)

---



## â–¶ï¸ How to Run Locally

Follow these steps to run the chatbot locally using Docker:

### 1. Make sure the following files are in your project:
- `app.py` â€“ the main Streamlit chatbot script
- `requirements.txt` â€“ list of Python dependencies
- `Dockerfile` â€“ to build the Docker image
- `.env` â€“ already included with an example key

### 2. Update the `.env` file

Open the `.env` file (already included in the repo) and **replace the placeholder key** with your actual key from [OpenRouter.ai](https://openrouter.ai/).




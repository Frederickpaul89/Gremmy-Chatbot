# 🤖 Gremmy-Chatbot

**GEN AI: Gremmy Chatbot made as a Knowledge Assistant**

Gremmy is a lightweight chatbot powered by Large Language Models (LLMs) that allows you to have natural conversations with an AI assistant. It’s designed to help users explore ideas, ask questions, or simply chat with a friendly, intelligent bot.

---

## 🌐 Try It Online

🚀 **Live Demo (Powered by Google Gemma LLM)**  
You can chat with Gremmy online via Hugging Face Spaces:  
🔗 [https://huggingface.co/spaces/Enoch1359/LLm_file](https://huggingface.co/spaces/Enoch1359/LLm_file)

---

## 📦 Features

- 💬 Chat with an AI assistant powered by LLM (Large Language Model)

---

## 🧪 Use Cases

- Have natural conversations with an AI
- Ask general knowledge or learning-related questions
- Use it as a virtual companion or tutor

---

## 🛠️ Tech Stack

- `Python 3.10+`
- `Streamlit` – for the web interface
- `OpenAI API` – for GPT-based responses
- `Google Gemma` – open-source LLM from Google  
- `dotenv` – to manage API keys securely
- `Docker` – for containerized deployment (optional)

---



## ▶️ How to Run Locally

Follow these steps to run the chatbot locally using Docker:

### 1. Make sure the following files are in your project:
- `app.py` – the main Streamlit chatbot script
- `requirements.txt` – list of Python dependencies
- `Dockerfile` – to build the Docker image
- `.env` – already included with an example key

### 2. Update the `.env` file

Open the `.env` file (already included in the repo) and **replace the placeholder key** with your actual key from [OpenRouter.ai](https://openrouter.ai/).



